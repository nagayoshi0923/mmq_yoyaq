#!/usr/bin/env python3
"""
ã‚·ãƒ³ãƒ—ãƒ«ãªHTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆã§ã‚«ã‚¿ãƒ­ã‚°ãƒšãƒ¼ã‚¸ã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’å–å¾—
"""

import requests
import re
import json
from bs4 import BeautifulSoup

def scrape_catalog():
    """ã‚«ã‚¿ãƒ­ã‚°ãƒšãƒ¼ã‚¸ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°"""
    url = "https://queenswaltz.jp/catalog"
    
    print(f"ã‚¢ã‚¯ã‚»ã‚¹ä¸­: {url}")
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ãƒšãƒ¼ã‚¸æ§‹é€ ã‚’ç¢ºèª
        print(f"ãƒšãƒ¼ã‚¸ã‚µã‚¤ã‚º: {len(response.text)} bytes")
        
        # ã‚«ãƒ¼ãƒ‰ã‚’æ¢ã™
        cards = soup.find_all(['div', 'article'], class_=re.compile(r'card|item|scenario', re.I))
        print(f"ã‚«ãƒ¼ãƒ‰å€™è£œ: {len(cards)}ä»¶")
        
        # ãƒ†ã‚­ã‚¹ãƒˆå…¨ä½“ã‹ã‚‰ã‚·ãƒŠãƒªã‚ªæƒ…å ±ã‚’æ¢ã™
        text = soup.get_text()
        
        # ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚¿ã‚°ã‚’æ¢ã™
        categories_found = []
        if 'ğŸ”°' in text or 'åˆå¿ƒè€…' in text:
            categories_found.append('åˆå¿ƒè€…å‘ã‘')
        if 'âœ¨' in text or 'æ–°ä½œ' in text:
            categories_found.append('æ–°ä½œ')
        if 'ğŸ“•' in text or 'ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ãƒ—ãƒ¬ã‚¤ãƒ³ã‚°' in text:
            categories_found.append('ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ãƒ—ãƒ¬ã‚¤ãƒ³ã‚°')
        if 'ğŸ”' in text or 'ãƒŸã‚¹ãƒ†ãƒªãƒ¼' in text:
            categories_found.append('ãƒŸã‚¹ãƒ†ãƒªãƒ¼')
        
        print(f"æ¤œå‡ºã‚«ãƒ†ã‚´ãƒªãƒ¼: {categories_found}")
        
        return text
        
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: {e}")
        return None

if __name__ == "__main__":
    result = scrape_catalog()
    if result:
        print(f"\næœ€åˆã®2000æ–‡å­—:\n{result[:2000]}")




